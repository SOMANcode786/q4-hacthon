"use strict";(globalThis.webpackChunkphysical_ai_humanoid_robotics=globalThis.webpackChunkphysical_ai_humanoid_robotics||[]).push([[22],{5272:(n,o,t)=>{t.r(o),t.d(o,{assets:()=>r,contentTitle:()=>s,default:()=>u,frontMatter:()=>c,metadata:()=>a,toc:()=>l});var e=t(4848),i=t(8453);const c={sidebar_label:"Voice-to-Action Systems",title:"Voice-to-Action Systems"},s="Voice-to-Action Systems",a={id:"module-5/voice-to-action",title:"Voice-to-Action Systems",description:"This module covers systems that translate human voice commands into robotic actions, enabling natural human-robot interaction through speech.",source:"@site/docs/module-5/voice-to-action.md",sourceDirName:"module-5",slug:"/module-5/voice-to-action",permalink:"/q4-hacthon/docs/module-5/voice-to-action",draft:!1,unlisted:!1,editUrl:"https://github.com/SOMANcode786/q4-hacthon/edit/main/docs/module-5/voice-to-action.md",tags:[],version:"current",frontMatter:{sidebar_label:"Voice-to-Action Systems",title:"Voice-to-Action Systems"},sidebar:"tutorialSidebar",previous:{title:"Introduction to Vision-Language-Action Systems",permalink:"/q4-hacthon/docs/module-5/vla-intro"},next:{title:"Cognitive Planning for Robots",permalink:"/q4-hacthon/docs/module-5/cognitive-planning"}},r={},l=[{value:"Learning Objectives",id:"learning-objectives",level:2},{value:"Content Coming Soon",id:"content-coming-soon",level:2}];function d(n){const o={h1:"h1",h2:"h2",li:"li",p:"p",ul:"ul",...(0,i.R)(),...n.components};return(0,e.jsxs)(e.Fragment,{children:[(0,e.jsx)(o.h1,{id:"voice-to-action-systems",children:"Voice-to-Action Systems"}),"\n",(0,e.jsx)(o.p,{children:"This module covers systems that translate human voice commands into robotic actions, enabling natural human-robot interaction through speech."}),"\n",(0,e.jsx)(o.h2,{id:"learning-objectives",children:"Learning Objectives"}),"\n",(0,e.jsxs)(o.ul,{children:["\n",(0,e.jsx)(o.li,{children:"Understand speech recognition and natural language processing"}),"\n",(0,e.jsx)(o.li,{children:"Learn to map language to robotic actions"}),"\n",(0,e.jsx)(o.li,{children:"Implement voice command interpretation"}),"\n",(0,e.jsx)(o.li,{children:"Handle ambiguous or complex voice instructions"}),"\n"]}),"\n",(0,e.jsx)(o.h2,{id:"content-coming-soon",children:"Content Coming Soon"}),"\n",(0,e.jsx)(o.p,{children:"This content is currently under development for the Physical AI & Humanoid Robotics course."})]})}function u(n={}){const{wrapper:o}={...(0,i.R)(),...n.components};return o?(0,e.jsx)(o,{...n,children:(0,e.jsx)(d,{...n})}):d(n)}},8453:(n,o,t)=>{t.d(o,{R:()=>s,x:()=>a});var e=t(6540);const i={},c=e.createContext(i);function s(n){const o=e.useContext(c);return e.useMemo(function(){return"function"==typeof n?n(o):{...o,...n}},[o,n])}function a(n){let o;return o=n.disableParentContext?"function"==typeof n.components?n.components(i):n.components||i:s(n.components),e.createElement(c.Provider,{value:o},n.children)}}}]);